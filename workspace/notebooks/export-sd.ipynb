{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AutoencoderKL\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import LMSDiscreteScheduler, UNet2DConditionModel\n",
    "from torch.utils.dlpack import from_dlpack, to_dlpack\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import CLIPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "unet/config.json: 100%|██████████| 772/772 [00:00<00:00, 2.21MB/s]\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/utils/hub_utils.py:336: FutureWarning: You are loading the variant fp16 from CompVis/stable-diffusion-v1-4 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that CompVis/stable-diffusion-v1-4 currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of CompVis/stable-diffusion-v1-4. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'CompVis/stable-diffusion-v1-4 is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/utils/hub_utils.py:336: FutureWarning: You are loading the variant fp16 from CompVis/stable-diffusion-v1-4 via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that CompVis/stable-diffusion-v1-4 currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of CompVis/stable-diffusion-v1-4. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'CompVis/stable-diffusion-v1-4 is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "diffusion_pytorch_model.bin: 100%|██████████| 1.72G/1.72G [08:22<00:00, 3.42MB/s]\n"
     ]
    }
   ],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "            \"CompVis/stable-diffusion-v1-4\",\n",
    "            subfolder=\"unet\",\n",
    "            revision=\"fp16\",\n",
    "            torch_dtype=torch.float16,\n",
    "            use_auth_token=True,\n",
    "        ).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Draw a dog\"\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_auth_token=True\n",
    ")\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "vae.forward = vae.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = Path(\"../triton_workspace/onnx_models\")\n",
    "\n",
    "ONNX_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/upsampling.py:149: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/upsampling.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.shape[0] >= 64:\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_kl.py:306: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.onnx.export(\n",
    "    vae,\n",
    "    (torch.randn(1, 4, 64, 64), False),\n",
    "    (ONNX_PATH / \"vae.onnx\").as_posix(),\n",
    "    input_names=[\"latent_sample\", \"return_dict\"],\n",
    "    output_names=[\"sample\"],\n",
    "    dynamic_axes={\n",
    "        \"latent_sample\": {0: \"batch\", 1: \"channels\", 2: \"height\", 3: \"width\"},\n",
    "    },\n",
    "    do_constant_folding=True,\n",
    "    opset_version=14,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:86: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1 or self.sliding_window is not None:\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/transformers/models/clip/modeling_clip.py:281: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/transformers/models/clip/modeling_clip.py:289: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/transformers/models/clip/modeling_clip.py:321: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/home/tran.duc.trungb/miniconda3/envs/triton-huggingface/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:5859: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_input = tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "torch.onnx.export(\n",
    "    text_encoder,\n",
    "    (text_input.input_ids.to(torch.int32)),\n",
    "    (ONNX_PATH / \"text_encoder.onnx\").as_posix(),\n",
    "    input_names=[\"input_ids\"],\n",
    "    output_names=[\"last_hidden_state\", \"pooler_output\"],\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch\", 1: \"sequence\"},\n",
    "    },\n",
    "    opset_version=14,\n",
    "    do_constant_folding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triton-huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
